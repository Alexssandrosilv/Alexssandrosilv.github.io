[
  {
    "objectID": "imd.html#pr√°tica",
    "href": "imd.html#pr√°tica",
    "title": "INTRODU√á√ÉO √Ä MINERA√á√ÉO DE DADOS - IMD",
    "section": "1 Pr√°tica",
    "text": "1 Pr√°tica\n\nExemplo de c√≥digo em RExemplo de c√≥digo em Python\n\n\nfizz_buzz &lt;- function(fbnums = 1:50) {\n  output &lt;- dplyr::case_when(\n    fbnums %% 15 == 0 ~ \"FizzBuzz\",\n    fbnums %% 3 == 0 ~ \"Fizz\",\n    fbnums %% 5 == 0 ~ \"Buzz\",\n    TRUE ~ as.character(fbnums)\n  )\n  print(output)\n}\n\n\ndef fizz_buzz(num):\n  if num % 15 == 0:\n  print(\"FizzBuzz\")\nelif num % 5 == 0:\n  print(\"Buzz\")\nelif num % 3 == 0:\n  print(\"Fizz\")\nelse:\n  print(num)"
  },
  {
    "objectID": "int_bayes.html#pr√°tica",
    "href": "int_bayes.html#pr√°tica",
    "title": "INTRODU√á√ÉO √Ä MINERA√á√ÉO DE DADOS - IMD",
    "section": "1 Pr√°tica",
    "text": "1 Pr√°tica\n\nExemplo de c√≥digo em RExemplo de c√≥digo em Python\n\n\nfizz_buzz &lt;- function(fbnums = 1:50) {\n  output &lt;- dplyr::case_when(\n    fbnums %% 15 == 0 ~ \"FizzBuzz\",\n    fbnums %% 3 == 0 ~ \"Fizz\",\n    fbnums %% 5 == 0 ~ \"Buzz\",\n    TRUE ~ as.character(fbnums)\n  )\n  print(output)\n}\n\n\ndef fizz_buzz(num):\n  if num % 15 == 0:\n  print(\"FizzBuzz\")\nelif num % 5 == 0:\n  print(\"Buzz\")\nelif num % 3 == 0:\n  print(\"Fizz\")\nelse:\n  print(num)"
  },
  {
    "objectID": "mlg.html#fam√≠lia-exponencial-can√¥nica",
    "href": "mlg.html#fam√≠lia-exponencial-can√¥nica",
    "title": "MODELOS LINEARES GENERALIZADOS - MLG",
    "section": "1 Fam√≠lia Exponencial Can√¥nica",
    "text": "1 Fam√≠lia Exponencial Can√¥nica\n\n\n1.1 Fam√≠lia Exponencial Biparam√©trica\n\n\nDizemos que uma vari√°vel aleat√≥ria Y (discreta ou cont√≠nua) pertence √† fam√≠lia exponencial biparam√©trica na forma can√¥nica, Y \\sim \\text{FE}(\\theta, \\phi), se sua fun√ß√£o densidade (ou de probabilidade) pode ser expressa por\n\n\nf(y;\\theta,\\phi) = \\exp\\left\\{ \\phi \\left[y\\theta - b(\\theta)  \\right] + c(y, \\phi) \\right\\} \\mathbb{I}_A(y)\n\nEm que as componentes s√£o:\n\n\n\\theta \\in \\mathbb{R} √© o par√¢metro can√¥nico da FE;\n\n\n\\phi &gt; 0 √© o par√¢metro de precis√£o;\n\n\nb(\\cdot) √© uma fun√ß√£o real, cont√≠nua e duas vezes diferenci√°vel;\n\n\nc(\\cdot\\,;\\cdot) √© uma fun√ß√£o real n√£o negativa;\n\n\nA √© o suporte da distribui√ß√£o de Y, que n√£o deve depender dos par√¢metros, nem de \\theta nem de \\phi.\n\n\n\n\n\n\n1.2 Fam√≠lia Exponencial Uniparam√©trica\n\n\nNote que, ao considerarmos o par√¢metro de precis√£o \\phi = 1, diz-se que a vari√°vel aleat√≥ria Y (discreta ou cont√≠nua) pertence √† fam√≠lia exponencial uniparam√©trica. Ou seja, Y \\sim \\text{FE}(\\theta), se sua fun√ß√£o densidade (ou de probabilidade) puder ser expressa por\n\n\nf(y;\\theta,\\phi) = \\exp\\left\\{ y\\theta - b(\\theta) + c(y) \\right\\} \\mathbb{I}_A(y)\n\n\n\n\n\n1.3 Distribui√ß√£o da Amostra (Fun√ß√£o de Verossmilhan√ßa)\n\n\nSeja \\bm{Y} = (Y_{1},Y_{2},\\cdots , Y_{n}) uma amostra aleat√≥ria de vari√°veis aleat√≥rias independentes provenientes de uma popula√ß√£o Y \\sim \\text{FE}(\\theta, \\phi), tal que a fun√ß√£o densidade (ou de probabilidade) de cada \\bm{Y_{i}}, com i = 1 ,\\cdots , n √© dada por\n\n\nf(y_{i};\\theta_{i},\\phi) = \\exp\\left\\{ \\phi \\left[y\\theta_{i} - b(\\theta_{i})  \\right] + c(y_{i}, \\phi) \\right\\} \\mathbb{I}_A(y) \\quad \\quad \\theta \\in \\mathbb{R}, \\quad \\phi &gt; 0\n\n Logo a fun√ß√£o de verossimilhan√ßa, com representa√ß√£o da FE √© dada por\n\n\n\\begin{aligned}\n\\mathcal{L}(\\boldsymbol{\\theta},\\phi)\n&= \\prod_{i = 1}^{n} f(y_{i};\\theta_{i},\\phi) \\\\\n&= \\prod_{i = 1}^{n} \\exp\\left\\{ \\phi \\left[y_{i}\\theta_{i} - b(\\theta_{i})  \\right] + c(y_{i}, \\phi) \\right\\} \\\\\n&= \\exp\\left\\{ \\phi \\left[y_{1}\\theta_{1} - b(\\theta_{1})  \\right] + c(y_{1}, \\phi) \\right\\} \\times \\cdots \\times \\exp\\left\\{ \\phi \\left[y_{n}\\theta_{n} - b(\\theta_{n})  \\right] + c(y_{n}, \\phi) \\right\\} \\\\\n&= \\exp\\left\\{ \\phi \\sum_{i=1}^{n} \\left[y_{i}\\theta_{i} - b(\\theta_{i})  \\right] + \\sum_{i=1}^{n} c(y_{i}, \\phi) \\right\\}\n\\end{aligned}\n\n\n\n\n1.4 Fun√ß√£o de Log-Verossmilhan√ßa\n\n\nA fun√ß√£o de log-verossimilhan√ßa com representa√ß√£o da FE √© dada por \n\n\\begin{aligned}\n\\mathcal{\\ell}(\\boldsymbol{\\theta},\\phi)  \n&= \\log \\left\\{ \\mathcal{L}(\\boldsymbol{\\theta},\\phi) \\right\\} \\\\\n&= \\log \\left\\{ \\exp\\left\\{ \\phi \\sum_{i=1}^{n} \\left[y_{i}\\theta_{i} - b(\\theta_{i})  \\right] + \\sum_{i=1}^{n} c(y_{i}, \\phi) \\right\\} \\right\\}\\\\\n&= \\phi \\sum_{i=1}^{n} \\left[y_{i}\\theta_{i} - b(\\theta_{i})  \\right] + \\sum_{i=1}^{n} c(y_{i}, \\phi)\n\\end{aligned}"
  },
  {
    "objectID": "mlg.html#exerc√≠cios",
    "href": "mlg.html#exerc√≠cios",
    "title": "MODELOS LINEARES GENERALIZADOS - MLG",
    "section": "2 Exerc√≠cios",
    "text": "2 Exerc√≠cios\n\n\nPara cada distribui√ß√£o da vari√°vel aleat√≥ria Y a seguir, mostraremos que ela pertence √† fam√≠lia exponencial can√¥nica, identificaremos os componentes e obteremos a esperan√ßa \\mu, a fun√ß√£o de vari√¢ncia V(\\mu) e a vari√¢ncia de Y.\n\n\nPoissonb) Binomialc) Binomial Negativad) Normale) Gammaf) Normal InversaDirichlet\n\n\n\n\\textcolor{blue}{\\text{Sobre o problema:}}\nA vari√°vel aleat√≥ria Y segue uma distribui√ß√£o de Poisson com taxa de crescimento \\mu. Sua fun√ß√£o de probabilidade (fun√ß√£o massa de probabilidade) √© dada por:\n\n\nf(y;\\mu) = \\frac{\\mu^{y} e^{-\\mu}} {y!}  \\mathbb{I}_{\\{\\mathbb{Z}^{+}\\}}(y) \\quad \\mu &gt; 0\n \n\\textcolor{blue}{\\text{Passo I: Importante, seja observador(a) üëÄ:}}\nFun√ß√£o Indicadora (suporte da vari√°vel aleat√≥ria): Note que o suporte da vari√°vel aleat√≥ria n√£o depende de nenhum par√¢metro. Como discutido anteriormente, esta depend√™ncia representaria um empecilho, pois, nesse caso, a fun√ß√£o de probabilidade n√£o se encaixaria na forma da fam√≠lia exponencial can√¥nica. No entanto, o fato de o suporte n√£o depender de \\theta nem de \\phi n√£o garante que a fun√ß√£o de probabilidade perten√ßa √† fam√≠lia exponencial can√¥nica. Iremos tentar parametriz√°-la e, caso n√£o seja poss√≠vel, justificaremos a impossibilidade.\nM√©dia: Veja se consegue identificar a m√©dia do modelo explicitamente na fun√ß√£o densidade (ou probabilidade). Lembre-se de que estamos interessados na m√©dia da distribui√ß√£o, pois ela √© o par√¢metro que aparece na forma can√¥nica da fam√≠lia exponencial ‚Äî o chamado par√¢metro can√¥nico denotado por \\theta. Quando trabalhamos com a fam√≠lia exponencial can√¥nica, um dos grandes trunfos dessa abordagem √© que podemos relacionar diretamente a m√©dia da distribui√ß√£o com os preditores por meio de uma fun√ß√£o de liga√ß√£o, o que ser√° fundamental para a constru√ß√£o dos Modelos Lineares Generalizados (GLMs).\nCaso a m√©dia n√£o esteja expl√≠cita na fun√ß√£o densidade, pode ser necess√°rio realizar algumas manipula√ß√µes adicionais para express√°-la de forma que possamos parametrizar corretamente. Essas transforma√ß√µes garantem que conseguimos aplicar a estrutura da fam√≠lia exponencial can√¥nica da maneira adequada.\nPor isso, √© fundamental termos informa√ß√µes detalhadas sobre a distribui√ß√£o com a qual estamos trabalhando. Essas informa√ß√µes s√£o essenciais para entendermos como os par√¢metros se relacionam e para identificarmos a m√©dia da distribui√ß√£o.‚Äù\nParametriza√ß√£o: Ops, quase me esqueci üòîüò∂! Lembre-se de que existem duas formas de parametriza√ß√£o na fam√≠lia exponencial em sua forma can√¥nica: a uniparam√©trica e a biparam√©trica. Para definir qual utilizar, √© necess√°rio observar o modelo em quest√£o. Como estamos lidando com o modelo de Poisson, que possui apenas um par√¢metro, adotaremos a parametriza√ß√£o uniparam√©trica (Neste exemplo).\nNesse caso, o par√¢metro de precis√£o, denotado por \\phi, √© assumido igual a 1.\n\n\\textcolor{blue}{\\text{Passo II: Parametriza√ß√£o da fam√≠lia exponencial can√¥nica.}}\nAgora, vamos deixar a enrola√ß√£o de lado e tentar parametrizar essa fun√ß√£o densidade (ou de probabilidade). Segure minha m√£o e vamos juntos nessa jornada üôÇ ‚Äî com confian√ßa! üòé\nDizemos que Y pertence √† fam√≠lia exponencial uniparam√©trica se for poss√≠vel expressar sua fun√ß√£o densidade (ou fun√ß√£o de probabilidade, no caso discreto) na forma:\n\n\nf(y;\\theta) = \\exp\\left\\{ y\\theta - b(\\theta) + c(y) \\right\\} \\mathbb{I}_A(y)\n \n\nA priori, √© importante fazermos uso de algumas propriedades logar√≠tmicas.\n\n f(y;\\mu)\\ = exp\\left\\{ \\log\\left[f(y;\\mu)\\right] \\right\\} \n\nVeja bem üëÄ, n√£o alteramos a express√£o ao aplicar a fun√ß√£o exponencial ao logaritmo. Essa opera√ß√£o ser√° √∫til e importante para a parametriza√ß√£o da fun√ß√£o densidade (ou fun√ß√£o de probabilidade). Aplicando exp\\left\\{ \\log\\left[f(y;\\mu)\\right] \\right\\}, estamos utilizando a propriedade fundamental dos logaritmos e exponenciais, ou seja, exp(\\log(x)) = x, o que nos permite manipular a express√£o sem alterar seu valor. Isso facilita a parametriza√ß√£o sem modificar a ess√™ncia da fun√ß√£o.\nAgora, basta substituirmos na express√£o acima pela fun√ß√£o de probabilidade da distribui√ß√£o de Poisson.\n\n f(y;\\mu)\\ = exp\\left\\{ \\log\\left[ \\frac{\\mu^{y} e^{-\\mu}} {y!}  \\right] \\right\\} \\mathbb{I}_{\\{\\mathbb{Z}^{+}\\}}(y)\n\nAplicando o logaritmo em cada termo da fun√ß√£o e utilizando a propriedade \\log\\left(\\dfrac{a}{b}\\right) = \\log(a) - \\log(b), onde a = \\mu^{y} e^{-\\mu} e b = y! obtemos:\n\n f(y;\\mu)\\ = exp\\left\\{ \\log (\\mu^{y}e^{-\\mu}) - log(y!) \\right\\} \\mathbb{I}_{\\{\\mathbb{Z}^{+}\\}}(y)\n\nAplicando a propriedade logar√≠tmica \\log\\left(a \\cdot b\\right) = \\log(a) + \\log(b), com a = \\mu^{y} e b = e^{-\\mu}, podemos reescrever \\log(\\mu^{y} e^{-\\mu}) como sendo \\log(\\mu^{y}) + \\log(e^{-\\mu}), portanto.\n\n f(y;\\mu)\\ = exp\\left\\{ \\log(\\mu^{y}) + \\log(e^{-\\mu}) - log(y!) \\right\\} \\mathbb{I}_{\\{\\mathbb{Z}^{+}\\}}(y) \n\\textcolor{blue}{\\text{Passo III: Momento de Reflex√£o ü§®, Veja Bem üëÄ}}\nUma d√∫vida comum √©: como saber se estou no caminho correto?\nLembre-se da estrutura da parametriza√ß√£o da fam√≠lia exponencial uniparam√©trica. Estamos tentando reescrever f(y;\\mu) nessa forma espec√≠fica. Ou seja, precisamos manipular a express√£o de modo que os componentes caracter√≠sticos dessa fam√≠lia apare√ßam\n \nf(y;\\theta) = \\exp\\left\\{ y\\theta - b(\\theta) + c(y) \\right\\} \\mathbb{I}_A(y)\n \n\n\n\n\n\n\nüìù Motiva√ß√£o ‚ù§Ô∏èüíµ‚úàÔ∏è\n\n\n\nEu sei, parece bem confuso üòî‚Ä¶ mas, assim como nas grandes hist√≥rias de amor, √†s vezes tudo come√ßa com d√∫vidas e incertezas, at√© que, pouco a pouco, cada pe√ßa encontra seu lugar. A matem√°tica e a estat√≠stica, como o amor, florescem quando temos paci√™ncia e acreditamos que tudo far√° sentido no final. üíå‚ú® Basta dar o seu melhor.\nE se n√£o fizer sentido, a gente faz algo n√£o param√©trico mesmo, n√©? üòú (Dorme que amanh√£ √© outro dia)\n\n\n\n\nContinuando o racioc√≠nio\nEstamos quase l√° üôÇüëç! Ao observarmos a express√£o, podemos notar que ainda precisamos de um y multiplicando um \\theta, n√£o √© mesmo? Lembre-se da dica sobre a m√©dia: a m√©dia da distribui√ß√£o de Poisson √© denotada por \\mu. Agora, se aplicarmos mais propriedades logar√≠tmicas, podemos usar a regra \\log(a^b) = b \\log(a), ou seja, \\log(\\mu^y) = y \\log(\\mu). Al√©m disso, podemos reescrever \\log(e^{-\\mu}) simplesmente como -\\mu, j√° que, como discutido anteriormente, \\log(e^a) = a.\n\n f(y;\\mu)\\ = exp\\left\\{y \\log(\\mu) -\\mu - log(y!) \\right\\} \\mathbb{I}_{\\{\\mathbb{Z}^{+}\\}}(y) \nOlha que m√°gico! ‚ú® Vamos comparar as duas express√µes agora:\n\n f(y;\\mu)\\ = exp\\left\\{y \\log(\\mu) -\\mu - log(y!) \\right\\} \\mathbb{I}_{\\{\\mathbb{Z}^{+}\\}}(y) f(y;\\theta) = \\exp\\left\\{ y\\theta - b(\\theta) + c(y) \\right\\} \\mathbb{I}_A(y)\n\nQue incr√≠vel ü§ó!\n\n\\textcolor{blue}{\\text{Passo IV: Identificar as componentes}}\nLogo as componentes s√£o:\n\n\n\\theta = \\log(\\mu) √© o par√¢metro can√¥nico da FE;\n\n\n\\phi = 1 √© o par√¢metro de precis√£o;\n\n\nb(\\theta) =  e^{\\theta}\n\\text{De modo que} \\quad \\theta = \\log \\mu \\quad \\Rightarrow \\quad e^\\theta = \\mu\n\n\nc(y) = \\log y!\n\n\nA(y) =  \\mathbb{Z^{+}} √© o suporte da distribui√ß√£o de Y, que n√£o depende dos par√¢metros.\n\n\n\n\\textcolor{blue}{\\text{Passo V: Propriedades da FE Can√¥nica}}\nCondi√ß√£o (Suporte):\n\\text{Resultado:} \\quad A(y)  \\quad \\text{n√£o pode depende dos par√¢metros}\n\\text{Prova:} \\quad A(y) =  \\mathbb{Z^{+}}\n\nCondi√ß√£o de Primeira Ordem (Derivada Primeira de b(\\theta)):\n\\text{Resultado:} \\quad b'(\\theta) = \\dfrac{\\delta b(\\theta)}{\\delta \\theta} = \\mathbb{E}[X] = \\mu\n\\text{Prova:} \\quad b'(\\theta) = \\dfrac{\\delta b(\\theta)}{\\delta \\theta} = \\dfrac{\\delta e^\\theta}{\\delta \\theta} = e^\\theta \\quad \\Rightarrow \\quad e^\\theta = \\mu \nCondi√ß√£o de Segunda Ordem (Derivada Segunda de b(\\theta)):\n\\text{Resultado:} \\quad b''(\\theta) = \\dfrac{\\delta^2 b(\\theta)}{\\delta \\theta} = \\dfrac{\\delta \\mu}{\\delta \\theta} = V(\\mu) = \\mu\n\\text{Prova:} \\quad b''(\\theta) = \\dfrac{\\delta^2 b(\\theta)}{\\delta \\theta} = \\dfrac{\\delta \\mu}{\\delta \\theta} = \\dfrac{\\delta e^\\theta}{\\delta \\theta} = e^\\theta  \\quad \\Rightarrow \\quad e^\\theta = \\mu\nOnde V(\\mu) √© chamada fun√ß√£o de vari√¢ncia e \\phi recebe o nome de par√¢metro de precis√£o porque quanto maior a vari√¢ncia de Y , menor ser√° o seu valor.\nConclus√£o\nA vari√°vel aleat√≥ria Y segue uma distribui√ß√£o de Poisson com taxa de crescimento \\mu, ou seja, Y \\sim \\text{Poisson}(\\mu). Como demonstramos, √© poss√≠vel reescrever sua fun√ß√£o de probabilidade na forma can√¥nica da fam√≠lia exponencial uniparam√©trica.\nLogo, Y pertence √† fam√≠lia exponencial com par√¢metro can√¥nico \\theta = \\log(\\mu), isto √©:\n\nY \\sim \\text{FE}(\\theta)\n\n\n\\textcolor{blue}{\\text{Passo VI: Distribui√ß√£o da Amostra (Fun√ß√£o de Verossmilhan√ßa)}}\n\n\\textcolor{blue}{\\text{Passo VII: Fun√ß√£o de Log-Verossmilhan√ßa}}\n\n\n\n\n\n\nInforma√ß√£o importante\n\n\n\nNote que at√© o momento fizemos tudo com bastante calma, explicando cada detalhe com carinho e aten√ß√£o. üíô\nMas agora, para n√£o alongarmos demais, vamos acelerar um pouquinho nas contas, t√° bom? Prometo que, mesmo assim, vamos continuar com cuidado e sem deixar voc√™ perdido. üôÇüòä‚úåÔ∏è\nSe algo parecer confuso, respira fundo ‚Äî voc√™ pode voltar e rever com calma quando quiser. Estamos juntos nessa jornada! ‚ú®\n\n\n\n\n\n\n\nP(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x = 0, 1, 2, \\dots\n\n\n\n\nP(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x = 0, 1, 2, \\dots\n\n\n\n\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right)\n\n\n\n\nP(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x = 0, 1, 2, \\dots\n\n\n\n\nP(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}, \\quad k = 0, 1, \\dots, n\n\n\n\n\nf(x_1, \\ldots, x_k \\;|\\; \\alpha_1, \\ldots, \\alpha_k) = \\frac{\\Gamma\\left(\\sum_{i=1}^{k} \\alpha_i \\right)}{\\prod_{i=1}^{k} \\Gamma(\\alpha_i)} \\prod_{i=1}^{k} x_i^{\\alpha_i - 1}, \\quad \\text{para } x_i \\geq 0 \\text{ e } \\sum_{i=1}^{k} x_i = 1."
  }
]