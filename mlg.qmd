---
#title: "MODELOS LINEARES GENERALIZADOS - MLG"                          # --> T√≠tulo principal do documento
# subtitle: "Nota√ß√µes de Aula"                                           # --> Subt√≠tulo (complementa o t√≠tulo)
#author: "**Alexssandro da Silva Oliveira - Acad√™mico de Estat√≠stica**" # --> Nome do autor (com negrito usando Quarto)
# date: ""                                                               # --> Data (em branco para n√£o exibir nada)
# date-format: short                                                     # --> Formato da data: curto (ex: 16/04/2025)
lang: pt
editor: visual                                                         # -----> Define o uso do editor visual (modo WYSIWYG no RStudio, por exemplo)
---

<br>


::: {.callout-note}
### Informa√ß√£o importante
**Resolu√ß√£o de Exerc√≠cios**
:::

<br>


## Fam√≠lia Exponencial Can√¥nica

<br>

### Fam√≠lia Exponencial Biparam√©trica

<br>

::: {style="text-align: justify"}
Dizemos que uma vari√°vel aleat√≥ria $Y$ (discreta ou cont√≠nua) pertence √† fam√≠lia exponencial biparam√©trica na forma can√¥nica, $Y \sim \text{FE}(\theta, \phi)$, se sua fun√ß√£o densidade (ou de probabilidade) pode ser expressa por

<br>

$$
f(y;\theta,\phi) = \exp\left\{ \phi \left[y\theta - b(\theta)  \right] + c(y, \phi) \right\} \mathbb{I}_A(y) 
$$

Em que as componentes s√£o:

<ul style="margin-left: 50px;">

<li style="margin-bottom: 10px;">

$\theta \in \mathbb{R}$ √© o <strong>par√¢metro can√¥nico</strong> da FE;

</li>

<li style="margin-bottom: 10px;">

$\phi > 0$ √© o <strong>par√¢metro de precis√£o</strong>;

</li>

<li style="margin-bottom: 10px;">

$b(\cdot)$ √© uma fun√ß√£o real, cont√≠nua e duas vezes diferenci√°vel;

</li>

<li style="margin-bottom: 10px;">

$c(\cdot\,;\cdot)$ √© uma fun√ß√£o real n√£o negativa;

</li>

<li style="margin-bottom: 10px;">

$A$ √© o suporte da distribui√ß√£o de $Y$, que n√£o deve depender dos par√¢metros, nem de $\theta$ nem de $\phi$.

</li>

</ul>

<br>
:::

### Fam√≠lia Exponencial Uniparam√©trica

<br>

::: {style="text-align: justify"}
Note que, ao considerarmos o par√¢metro de precis√£o $\phi = 1$, diz-se que a vari√°vel aleat√≥ria $Y$ (discreta ou cont√≠nua) pertence √† fam√≠lia exponencial uniparam√©trica. Ou seja, $Y \sim \text{FE}(\theta)$, se sua fun√ß√£o densidade (ou de probabilidade) puder ser expressa por

<br>

$$
f(y;\theta) = \exp\left\{ y\theta - b(\theta) + c(y) \right\} \mathbb{I}_A(y) 
$$
:::



<br>

### Distribui√ß√£o da Amostra (Fun√ß√£o de Verossmilhan√ßa)

<br>

::: {style="text-align: justify"}

Seja $\bm{Y} = (Y_{1},Y_{2},\cdots , Y_{n})$ uma amostra aleat√≥ria de vari√°veis aleat√≥rias independentes provenientes de uma popula√ß√£o $Y \sim \text{FE}(\theta, \phi)$, tal que a fun√ß√£o densidade (ou de probabilidade) de cada $\bm{Y_{i}}$, com $i = 1 ,\cdots , n$ √© dada por

<br>

$$
f(y_{i};\theta_{i},\phi) = \exp\left\{ \phi \left[y\theta_{i} - b(\theta_{i})  \right] + c(y_{i}, \phi) \right\} \mathbb{I}_A(y) \quad \quad \theta \in \mathbb{R}, \quad \phi > 0
$$

<br> Logo a fun√ß√£o de verossimilhan√ßa, com representa√ß√£o da **FE** √© dada por

<br>

$$
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta},\phi) 
&= \prod_{i = 1}^{n} f(y_{i};\theta_{i},\phi) \\
&= \prod_{i = 1}^{n} \exp\left\{ \phi \left[y_{i}\theta_{i} - b(\theta_{i})  \right] + c(y_{i}, \phi) \right\} \\
&= \exp\left\{ \phi \left[y_{1}\theta_{1} - b(\theta_{1})  \right] + c(y_{1}, \phi) \right\} \times \cdots \times \exp\left\{ \phi \left[y_{n}\theta_{n} - b(\theta_{n})  \right] + c(y_{n}, \phi) \right\} \\
&= \exp\left\{ \phi \sum_{i=1}^{n} \left[y_{i}\theta_{i} - b(\theta_{i})  \right] + \sum_{i=1}^{n} c(y_{i}, \phi) \right\}
\end{aligned}
$$
:::

### Fun√ß√£o de Log-Verossmilhan√ßa

<br>

::: {style="text-align: justify"}


A fun√ß√£o de log-verossimilhan√ßa com representa√ß√£o da **FE** √© dada por 

<br>

$$
\begin{aligned}
\mathcal{\ell}(\boldsymbol{\theta},\phi)  
&= \log \left\{ \mathcal{L}(\boldsymbol{\theta},\phi) \right\} \\
&= \log \left\{ \exp\left\{ \phi \sum_{i=1}^{n} \left[y_{i}\theta_{i} - b(\theta_{i})  \right] + \sum_{i=1}^{n} c(y_{i}, \phi) \right\} \right\}\\
&= \phi \sum_{i=1}^{n} \left[y_{i}\theta_{i} - b(\theta_{i})  \right] + \sum_{i=1}^{n} c(y_{i}, \phi) 
\end{aligned}
$$
:::


<br>

## Exerc√≠cios


<br>

::: {style="text-align: justify"}

Para cada distribui√ß√£o da vari√°vel aleat√≥ria $Y$ a seguir, mostraremos que ela pertence √† fam√≠lia exponencial can√¥nica, identificaremos os componentes e obteremos a esperan√ßa $\mu$, a fun√ß√£o de vari√¢ncia $V(\mu)$ e a vari√¢ncia de $Y$.

<br>

::: panel-tabset

## Poisson

<div style="text-align: justify">

**$\textcolor{blue}{\text{Sobre o problema:}}$**

A vari√°vel aleat√≥ria $Y$ segue uma distribui√ß√£o de Poisson com taxa de crescimento $\mu$. Sua fun√ß√£o de probabilidade (fun√ß√£o massa de probabilidade) √© dada por


<br>

$$
f(y;\mu) = \frac{\mu^{y} e^{-\mu}} {y!}  \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y) \quad \mu > 0
$$
<br>
  
**$\textcolor{blue}{\text{Passo I: Importante, seja observador(a) üëÄ:}}$**

**Fun√ß√£o Indicadora (suporte da vari√°vel aleat√≥ria):** Note que o suporte da vari√°vel aleat√≥ria n√£o depende de nenhum par√¢metro. Como discutido anteriormente, esta depend√™ncia representaria um empecilho, pois, nesse caso, a fun√ß√£o de probabilidade n√£o se encaixaria na forma da fam√≠lia exponencial can√¥nica. No entanto, o fato de o suporte n√£o depender de $\theta$ nem de $\phi$ n√£o garante que a fun√ß√£o de probabilidade perten√ßa √† fam√≠lia exponencial can√¥nica. Iremos tentar parametriz√°-la e, caso n√£o seja poss√≠vel, justificaremos a impossibilidade.

**M√©dia:** Veja se consegue identificar a m√©dia do modelo explicitamente na fun√ß√£o densidade (ou probabilidade). Lembre-se de que estamos interessados na m√©dia da distribui√ß√£o, pois ela √© o par√¢metro que aparece na forma can√¥nica da fam√≠lia exponencial ‚Äî o chamado par√¢metro can√¥nico denotado por $\theta$. Quando trabalhamos com a fam√≠lia exponencial can√¥nica, um dos grandes trunfos dessa abordagem √© que podemos relacionar diretamente a m√©dia da distribui√ß√£o com os preditores por meio de uma fun√ß√£o de liga√ß√£o, o que ser√° fundamental para a constru√ß√£o dos Modelos Lineares Generalizados (GLMs).

Caso a m√©dia n√£o esteja expl√≠cita na fun√ß√£o densidade, pode ser necess√°rio realizar algumas manipula√ß√µes adicionais para express√°-la de forma que possamos parametrizar corretamente. Essas transforma√ß√µes garantem que conseguimos aplicar a estrutura da fam√≠lia exponencial can√¥nica da maneira adequada.

Por isso, √© fundamental termos informa√ß√µes detalhadas sobre a distribui√ß√£o com a qual estamos trabalhando. Essas informa√ß√µes s√£o essenciais para entendermos como os par√¢metros se relacionam e para identificarmos a m√©dia da distribui√ß√£o."

**Parametriza√ß√£o:** Ops, quase me esqueci üòîüò∂! Lembre-se de que existem duas formas de **parametriza√ß√£o na fam√≠lia exponencial** em sua forma can√¥nica: a **uniparam√©trica** e a **biparam√©trica**. Para definir qual utilizar, √© necess√°rio observar o modelo em quest√£o. Como estamos lidando com o modelo de **Poisson**, que possui apenas um par√¢metro, adotaremos a parametriza√ß√£o uniparam√©trica (Neste exemplo).

Nesse caso, o par√¢metro de precis√£o, denotado por $\phi$, √© assumido igual a 1.

<br>

**$\textcolor{blue}{\text{Passo II: Parametriza√ß√£o da fam√≠lia exponencial can√¥nica.}}$**

Agora, vamos deixar a enrola√ß√£o de lado e tentar parametrizar essa fun√ß√£o densidade (ou de probabilidade). Segure minha m√£o e vamos juntos nessa jornada üôÇ ‚Äî com confian√ßa! üòé

Dizemos que $Y$ pertence √† fam√≠lia exponencial uniparam√©trica se for poss√≠vel expressar sua fun√ß√£o densidade (ou fun√ß√£o de probabilidade, no caso discreto) na forma:

<br>

$$
f(y;\theta) = \exp\left\{ y\theta - b(\theta) + c(y) \right\} \mathbb{I}_A(y) 
$$
<br>

A priori, √© importante fazermos uso de algumas propriedades logar√≠tmicas.

<br>

$$ f(y;\mu)\ = exp\left\{ \log\left[f(y;\mu)\right] \right\} $$

<br>

Veja bem üëÄ, n√£o alteramos a express√£o ao aplicar a fun√ß√£o exponencial ao logaritmo. Essa opera√ß√£o ser√° √∫til e importante para a parametriza√ß√£o da fun√ß√£o densidade (ou fun√ß√£o de probabilidade). Aplicando $exp\left\{ \log\left[f(y;\mu)\right] \right\}$, estamos utilizando a propriedade fundamental dos logaritmos e exponenciais, ou seja, $exp(\log(x)) = x$, o que nos permite manipular a express√£o sem alterar seu valor. Isso facilita a parametriza√ß√£o sem modificar a ess√™ncia da fun√ß√£o.


Agora, basta substituirmos na express√£o acima pela fun√ß√£o de probabilidade da distribui√ß√£o de Poisson.


<br>

$$ f(y;\mu)\ = exp\left\{ \log\left[ \frac{\mu^{y} e^{-\mu}} {y!}  \right] \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$

<br>

Aplicando o logaritmo em cada termo da fun√ß√£o e utilizando a propriedade $\log\left(\dfrac{a}{b}\right) = \log(a) - \log(b)$, onde $a = \mu^{y} e^{-\mu}$ e $b = y!$ obtemos:

<br>

$$ f(y;\mu)\ = exp\left\{ \log (\mu^{y}e^{-\mu}) - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$

<br>


Aplicando a propriedade logar√≠tmica $\log\left(a \cdot b\right) = \log(a) + \log(b)$, com $a = \mu^{y}$ e $b = e^{-\mu}$, podemos reescrever $\log(\mu^{y} e^{-\mu})$ como sendo $\log(\mu^{y}) + \log(e^{-\mu})$, portanto.


<br>

$$ f(y;\mu)\ = exp\left\{ \log(\mu^{y}) + \log(e^{-\mu}) - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$
<br>

**$\textcolor{blue}{\text{Passo III: Momento de Reflex√£o ü§®, Veja Bem üëÄ}}$**

**Uma d√∫vida comum √©: como saber se estou no caminho correto?**


Lembre-se da estrutura da parametriza√ß√£o da fam√≠lia exponencial uniparam√©trica. Estamos tentando reescrever $f(y;\mu)$ nessa forma espec√≠fica. Ou seja, precisamos manipular a express√£o de modo que os componentes caracter√≠sticos dessa fam√≠lia apare√ßam

<br>
$$
f(y;\theta) = \exp\left\{ y\theta - b(\theta) + c(y) \right\} \mathbb{I}_A(y) 
$$
<br>

::: {.callout-note}
### üìù Motiva√ß√£o ‚ù§Ô∏èüíµ‚úàÔ∏è

Eu sei, parece bem confuso üòî‚Ä¶ mas, assim como nas grandes hist√≥rias de amor, √†s vezes tudo come√ßa com d√∫vidas e incertezas, at√© que, pouco a pouco, cada pe√ßa encontra seu lugar. A matem√°tica e a estat√≠stica, como o amor, florescem quando temos paci√™ncia e acreditamos que tudo far√° sentido no final. üíå‚ú® Basta dar o seu melhor.

E se n√£o fizer sentido, a gente faz algo n√£o param√©trico mesmo, n√©? üòú (Dorme que amanh√£ √© outro dia)

:::

<br>

<br>

**Continuando o racioc√≠nio**

Estamos quase l√° üôÇüëç! Ao observarmos a express√£o, podemos notar que ainda precisamos de um $y$ multiplicando um $\theta$, n√£o √© mesmo? Lembre-se da dica sobre a m√©dia: a m√©dia da distribui√ß√£o de Poisson √© denotada por $\mu$. Agora, se aplicarmos mais propriedades logar√≠tmicas, podemos usar a regra $\log(a^b) = b \log(a)$, ou seja, $\log(\mu^y) = y \log(\mu)$. Al√©m disso, podemos reescrever $\log(e^{-\mu})$ simplesmente como $-\mu$, j√° que, como discutido anteriormente, $\log(e^a) = a$.


<br>

$$ f(y;\mu)\ = exp\left\{y \log(\mu) -\mu - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$
<br>


Olha que m√°gico! ‚ú® Vamos comparar as duas express√µes agora:

<br>

$$ f(y;\mu)\ = exp\left\{y \log(\mu) -\mu - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$
$$f(y;\theta) = \exp\left\{ y\theta - b(\theta) + c(y) \right\} \mathbb{I}_A(y)$$

<br>

Que incr√≠vel ü§ó! 

<br>

**$\textcolor{blue}{\text{Passo IV: Identificar as componentes}}$**

Logo as componentes s√£o:

<ul style="margin-left: 50px;">

<li style="margin-bottom: 10px;">

$\theta = \log(\mu)$ √© o <strong>par√¢metro can√¥nico</strong> da FE;

</li>

<li style="margin-bottom: 10px;">

$\phi = 1$ √© o <strong>par√¢metro de precis√£o</strong>;

</li>

<li style="margin-bottom: 10px;">

$b(\theta) =  e^{\theta}$ 

$$\text{De modo que} \quad \theta = \log \mu \quad \Rightarrow \quad e^\theta = \mu$$

</li>

<li style="margin-bottom: 10px;">

$c(y) = \log y!$

</li>

<li style="margin-bottom: 10px;">

$A(y) =  \mathbb{Z^{+}}$ √© o suporte da distribui√ß√£o de $Y$, que n√£o depende dos par√¢metros.
</li>

</ul>

<br>

**$\textcolor{blue}{\text{Passo V: Propriedades da FE Can√¥nica}}$**


**Condi√ß√£o (Suporte):** 

$$\text{Resultado:} \quad A(y)  \quad \text{n√£o pode depende dos par√¢metros}$$

$$\text{Prova:} \quad A(y) =  \mathbb{Z^{+}}$$ 

<br>

**Condi√ß√£o de Primeira Ordem (Derivada Primeira de $b(\theta)$):** 

$$\text{Resultado:} \quad b'(\theta) = \dfrac{\delta b(\theta)}{\delta \theta} = \mathbb{E}[X] = \mu$$

$$\text{Prova:} \quad b'(\theta) = \dfrac{\delta b(\theta)}{\delta \theta} = \dfrac{\delta e^\theta}{\delta \theta} = e^\theta \quad \Rightarrow \quad e^\theta = \mu$$
<br>

**Condi√ß√£o de Segunda Ordem (Derivada Segunda de $b(\theta)$):** 

$$\text{Resultado:} \quad b''(\theta) = \dfrac{\delta^2 b(\theta)}{\delta \theta} = \dfrac{\delta \mu}{\delta \theta} = V(\mu) = \mu$$

$$\text{Prova:} \quad b''(\theta) = \dfrac{\delta^2 b(\theta)}{\delta \theta} = \dfrac{\delta \mu}{\delta \theta} = \dfrac{\delta e^\theta}{\delta \theta} = e^\theta  \quad \Rightarrow \quad e^\theta = \mu$$

Onde $V(\mu)$ √© chamada fun√ß√£o de vari√¢ncia e $\phi$ recebe o nome de par√¢metro de precis√£o porque quanto maior a vari√¢ncia de Y , menor ser√° o seu valor.


**Conclus√£o**  

A vari√°vel aleat√≥ria $Y$ segue uma distribui√ß√£o de Poisson com taxa de crescimento $\mu$, ou seja, $Y \sim \text{Poisson}(\mu)$. Como demonstramos, √© poss√≠vel reescrever sua fun√ß√£o de probabilidade na forma can√¥nica da fam√≠lia exponencial uniparam√©trica.  

Logo, $Y$ pertence √† fam√≠lia exponencial com par√¢metro can√¥nico $\theta = \log(\mu)$, isto √©:  
$$
Y \sim \text{FE}(\theta)
$$

<br>


**$\textcolor{blue}{\text{Passo VI: Distribui√ß√£o da Amostra (Fun√ß√£o de Verossmilhan√ßa)}}$**

Como discutido anteriormente, ao expressarmos a fun√ß√£o de densidade de probabilidade na forma da fam√≠lia exponencial, torna-se poss√≠vel construir a fun√ß√£o de verossimilhan√ßa por meio do produt√≥rio das densidades associadas a cada observa√ß√£o. Essa formula√ß√£o √© vi√°vel gra√ßas √† suposi√ß√£o de que as observa√ß√µes s√£o independentes e identicamente distribu√≠das, logo:


$$
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) 
&= \prod_{i = 1}^{n} f(y_{i};\theta_{i}) \\
&= \prod_{i = 1}^{n} \exp\left\{ y_{i}\theta_{i} - b(\theta_{i})   + c(y_{i})\right\} \\
&= \exp\left\{ y_{1}\theta_{1} - b(\theta_{1}) + c(y_{1}) \right\} \times \cdots \times \exp\left\{y_{n}\theta_{n} - b(\theta_{n}) + c(y_{n}) \right\} \\
&= \exp\left\{\sum_{i=1}^{n} y_{i}\theta_{i} - \sum_{i=1}^{n} b(\theta_{i})   + \sum_{i=1}^{n} c(y_{i}) \right\}
\end{aligned}
$$
<br>

Agora, basta substituirmos $f(y_{i};\theta_{i})$ na express√£o acima pela fun√ß√£o de probabilidade da distribui√ß√£o de Poisson, logo:


<br>

$$
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) 
&= \prod_{i = 1}^{n} \left\{\frac{\mu_{i}^{y_i} e^{-\mu_{i}}} {y_{i}!}\right\} \\
&= \prod_{i = 1}^{n} exp\left\{y_{i} \log(\mu_{i}) - e^{\mu_{i}} - log(y_{i}!) \right\} \\
&= exp\left\{y_{1} \log(\mu_{1}) - e^{\mu_{1}} - log(y_{1}!) \right\} \times \cdots \times exp\left\{y_{n} \log(\mu_{n}) - e^{\mu_{n}} - log(y_{n}!) \right\} \\
&= \exp\left\{\sum_{i=1}^{n} y_{i} \log(\mu_{i}) - \sum_{i=1}^{n} e^{\mu_{i}}   + \sum_{i=1}^{n} log(y_{i}!) \right\}
\end{aligned}
$$

<br>

**$\textcolor{blue}{\text{Passo VII: Fun√ß√£o de Log-Verossmilhan√ßa}}$**

A fun√ß√£o de log-verossimilhan√ßa com representa√ß√£o da **FE** √© dada por 

<br>

$$
\begin{aligned}
\mathcal{\ell}(\boldsymbol{\theta})  
&= \log \left\{ \mathcal{L}(\boldsymbol{\theta}) \right\} \\
&= \log \left\{ \exp\left\{\sum_{i=1}^{n} y_{i} \log(\mu_{i}) - \sum_{i=1}^{n} \mu_{i}   + \sum_{i=1}^{n} log(y_{i}!) \right\} \right\}\\
&= \sum_{i=1}^{n} y_{i} \log(\mu_{i}) - \sum_{i=1}^{n} \mu_{i}   + \sum_{i=1}^{n} log(y_{i}!)
\end{aligned}
$$



::: {.callout-note}
### Informa√ß√£o importante
**Note que at√© o momento fizemos tudo com bastante calma, explicando cada detalhe com carinho e aten√ß√£o. üíô  
Mas agora, para n√£o alongarmos demais, vamos acelerar um pouquinho nas contas, t√° bom? Prometo que, mesmo assim, vamos continuar com cuidado e sem deixar voc√™ perdido. üôÇüòä‚úåÔ∏è  
Se algo parecer confuso, respira fundo ‚Äî voc√™ pode voltar e rever com calma quando quiser. Estamos juntos nessa jornada! ‚ú®**
:::

<br>


</div>



## b) Binomial


$$
P(X = x) = \frac{e^{-\lambda} \lambda^x}{x!}, \quad x = 0, 1, 2, \dots
$$


## c) Binomial Negativa


$$
P(X = x) = \frac{e^{-\lambda} \lambda^x}{x!}, \quad x = 0, 1, 2, \dots
$$





## d) Normal

<div style="text-align: justify">

**$\textcolor{blue}{\text{Sobre o problema:}}$**

A vari√°vel aleat√≥ria $Y$ tem distribui√ß√£o Normal com m√©dia $\mu$ e vari√¢ncia $\sigma^2$. Sua fun√ß√£o densidade de probabilidade √© dada por


<br>

$$
f(y;\mu,\sigma^2) = \dfrac{1}{\sqrt{2 \pi \sigma^2}} exp \left[ -\dfrac{(y - \mu)^2} {2\sigma^2}  \right] \mathbb{I}_{\{\mathbb{R}}\}(y), \quad \mu \in \mathbb{R}, \quad \sigma^2 > 0
$$
<br>
  
**$\textcolor{blue}{\text{Passo I: Importante, seja observador(a) üëÄ:}}$**

**Fun√ß√£o Indicadora (suporte da vari√°vel aleat√≥ria):** Note que o suporte da vari√°vel aleat√≥ria n√£o depende de nenhum par√¢metro. 

**M√©dia:** Veja se consegue identificar a m√©dia do modelo explicitamente na fun√ß√£o densidade (ou probabilidade).

Caso a m√©dia n√£o esteja expl√≠cita na fun√ß√£o densidade, pode ser necess√°rio realizar algumas manipula√ß√µes adicionais para express√°-la de forma que possamos parametrizar corretamente.

**Parametriza√ß√£o:**  Como estamos lidando com o modelo de **Normal**, que possui dois par√¢metros, adotaremos a parametriza√ß√£o biparam√©trica 

<br>

**$\textcolor{blue}{\text{Passo II: Parametriza√ß√£o da fam√≠lia exponencial can√¥nica.}}$**

Dizemos que $Y$ pertence √† fam√≠lia exponencial biparam√©trica se for poss√≠vel expressar sua fun√ß√£o densidade na forma:

<br>

$$
f(y;\theta,\phi) = \exp\left\{ \phi \left[y\theta - b(\theta)  \right] + c(y, \phi) \right\} \mathbb{I}_A(y) 
$$
<br>

Iremos reescrever a  fun√ß√£o densidade $f(y;\theta,\phi)$ para facilitar a sua manipula√ß√£o

$$
\begin{aligned}
f(y;\mu,\sigma^2) 
&= \dfrac{1}{\sqrt{2 \pi \sigma^2}} exp \left( -\dfrac{(y - \mu)^2} {2\sigma^2}  \right) \mathbb{I}_{\{\mathbb{R}}\}(y) \\
&= (2 \pi \sigma^2)^{-\frac{1}{2}} exp\left( -\dfrac{(y - \mu)^2} {2\sigma^2}  \right) \mathbb{I}_{\{\mathbb{R}}\}(y) \\
\end{aligned}
$$

A priori, √© importante fazermos uso de algumas propriedades logar√≠tmicas.

<br>

$$
\begin{aligned}
f(y;\mu, \sigma^2)\ &= exp\left\{ \log\left[f(y;\mu,\sigma^2)\right] \right\} \\
&= exp\left\{ \log\left[ \dfrac{1}{\sqrt{2 \pi \sigma^2}} \left( -\dfrac{(y - \mu)^2} {2\sigma^2}  \right)\right] \right\}\mathbb{I}_{\{\mathbb{R}}\}(y)\\
&= exp\left\{ \log\left[ \dfrac{1}{\sqrt{2 \pi \sigma^2}} \left( -\dfrac{(y - \mu)^2} {2\sigma^2}  \right)\right] \right\}\mathbb{I}_{\{\mathbb{R}}\}(y)\\

&= \prod_{i = 1}^{n} f(y_{i};\theta_{i}) \\
&= \prod_{i = 1}^{n} \exp\left\{ y_{i}\theta_{i} - b(\theta_{i})   + c(y_{i})\right\} \\
&= \exp\left\{ y_{1}\theta_{1} - b(\theta_{1}) + c(y_{1}) \right\} \times \cdots \times \exp\left\{y_{n}\theta_{n} - b(\theta_{n}) + c(y_{n}) \right\} \\
&= \exp\left\{\sum_{i=1}^{n} y_{i}\theta_{i} - \sum_{i=1}^{n} b(\theta_{i})   + \sum_{i=1}^{n} c(y_{i}) \right\}
\end{aligned}
$$

<br>


$$ f(y;\mu, \sigma^2)\ = exp\left\{ \log\left[f(y;\mu,\sigma^2)\right] \right\} $$

<br>

Veja bem üëÄ, n√£o alteramos a express√£o ao aplicar a fun√ß√£o exponencial ao logaritmo. Essa opera√ß√£o ser√° √∫til e importante para a parametriza√ß√£o da fun√ß√£o densidade (ou fun√ß√£o de probabilidade). Aplicando $exp\left\{ \log\left[f(y;\mu)\right] \right\}$, estamos utilizando a propriedade fundamental dos logaritmos e exponenciais, ou seja, $exp(\log(x)) = x$, o que nos permite manipular a express√£o sem alterar seu valor. Isso facilita a parametriza√ß√£o sem modificar a ess√™ncia da fun√ß√£o.


Agora, basta substituirmos na express√£o acima pela fun√ß√£o de densidade de probabilidade do modelo normal.


<br>

$$ f(y;\mu)\ = exp\left\{ \log\left[ \frac{\mu^{y} e^{-\mu}} {y!}  \right] \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$

<br>

Aplicando o logaritmo em cada termo da fun√ß√£o e utilizando a propriedade $\log\left(\dfrac{a}{b}\right) = \log(a) - \log(b)$, onde $a = \mu^{y} e^{-\mu}$ e $b = y!$ obtemos:

<br>

$$ f(y;\mu)\ = exp\left\{ \log (\mu^{y}e^{-\mu}) - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$

<br>


Aplicando a propriedade logar√≠tmica $\log\left(a \cdot b\right) = \log(a) + \log(b)$, com $a = \mu^{y}$ e $b = e^{-\mu}$, podemos reescrever $\log(\mu^{y} e^{-\mu})$ como sendo $\log(\mu^{y}) + \log(e^{-\mu})$, portanto.


<br>

$$ f(y;\mu)\ = exp\left\{ \log(\mu^{y}) + \log(e^{-\mu}) - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$
<br>

**$\textcolor{blue}{\text{Passo III: Momento de Reflex√£o ü§®, Veja Bem üëÄ}}$**

**Uma d√∫vida comum √©: como saber se estou no caminho correto?**


Lembre-se da estrutura da parametriza√ß√£o da fam√≠lia exponencial uniparam√©trica. Estamos tentando reescrever $f(y;\mu)$ nessa forma espec√≠fica. Ou seja, precisamos manipular a express√£o de modo que os componentes caracter√≠sticos dessa fam√≠lia apare√ßam

<br>
$$
f(y;\theta) = \exp\left\{ y\theta - b(\theta) + c(y) \right\} \mathbb{I}_A(y) 
$$
<br>

::: {.callout-note}
### üìù Motiva√ß√£o ‚ù§Ô∏èüíµ‚úàÔ∏è

Eu sei, parece bem confuso üòî‚Ä¶ mas, assim como nas grandes hist√≥rias de amor, √†s vezes tudo come√ßa com d√∫vidas e incertezas, at√© que, pouco a pouco, cada pe√ßa encontra seu lugar. A matem√°tica e a estat√≠stica, como o amor, florescem quando temos paci√™ncia e acreditamos que tudo far√° sentido no final. üíå‚ú® Basta dar o seu melhor.

E se n√£o fizer sentido, a gente faz algo n√£o param√©trico mesmo, n√©? üòú (Dorme que amanh√£ √© outro dia)

:::

<br>

<br>

**Continuando o racioc√≠nio**

Estamos quase l√° üôÇüëç! Ao observarmos a express√£o, podemos notar que ainda precisamos de um $y$ multiplicando um $\theta$, n√£o √© mesmo? Lembre-se da dica sobre a m√©dia: a m√©dia da distribui√ß√£o de Poisson √© denotada por $\mu$. Agora, se aplicarmos mais propriedades logar√≠tmicas, podemos usar a regra $\log(a^b) = b \log(a)$, ou seja, $\log(\mu^y) = y \log(\mu)$. Al√©m disso, podemos reescrever $\log(e^{-\mu})$ simplesmente como $-\mu$, j√° que, como discutido anteriormente, $\log(e^a) = a$.


<br>

$$ f(y;\mu)\ = exp\left\{y \log(\mu) -\mu - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$
<br>


Olha que m√°gico! ‚ú® Vamos comparar as duas express√µes agora:

<br>

$$ f(y;\mu)\ = exp\left\{y \log(\mu) -\mu - log(y!) \right\} \mathbb{I}_{\{\mathbb{Z}^{+}\}}(y)$$
$$f(y;\theta) = \exp\left\{ y\theta - b(\theta) + c(y) \right\} \mathbb{I}_A(y)$$

<br>

Que incr√≠vel ü§ó! 

<br>

**$\textcolor{blue}{\text{Passo IV: Identificar as componentes}}$**

Logo as componentes s√£o:

<ul style="margin-left: 50px;">

<li style="margin-bottom: 10px;">

$\theta = \log(\mu)$ √© o <strong>par√¢metro can√¥nico</strong> da FE;

</li>

<li style="margin-bottom: 10px;">

$\phi = 1$ √© o <strong>par√¢metro de precis√£o</strong>;

</li>

<li style="margin-bottom: 10px;">

$b(\theta) =  e^{\theta}$ 

$$\text{De modo que} \quad \theta = \log \mu \quad \Rightarrow \quad e^\theta = \mu$$

</li>

<li style="margin-bottom: 10px;">

$c(y) = \log y!$

</li>

<li style="margin-bottom: 10px;">

$A(y) =  \mathbb{Z^{+}}$ √© o suporte da distribui√ß√£o de $Y$, que n√£o depende dos par√¢metros.
</li>

</ul>

<br>

**$\textcolor{blue}{\text{Passo V: Propriedades da FE Can√¥nica}}$**


**Condi√ß√£o (Suporte):** 

$$\text{Resultado:} \quad A(y)  \quad \text{n√£o pode depende dos par√¢metros}$$

$$\text{Prova:} \quad A(y) =  \mathbb{Z^{+}}$$ 

<br>

**Condi√ß√£o de Primeira Ordem (Derivada Primeira de $b(\theta)$):** 

$$\text{Resultado:} \quad b'(\theta) = \dfrac{\delta b(\theta)}{\delta \theta} = \mathbb{E}[X] = \mu$$

$$\text{Prova:} \quad b'(\theta) = \dfrac{\delta b(\theta)}{\delta \theta} = \dfrac{\delta e^\theta}{\delta \theta} = e^\theta \quad \Rightarrow \quad e^\theta = \mu$$
<br>

**Condi√ß√£o de Segunda Ordem (Derivada Segunda de $b(\theta)$):** 

$$\text{Resultado:} \quad b''(\theta) = \dfrac{\delta^2 b(\theta)}{\delta \theta} = \dfrac{\delta \mu}{\delta \theta} = V(\mu) = \mu$$

$$\text{Prova:} \quad b''(\theta) = \dfrac{\delta^2 b(\theta)}{\delta \theta} = \dfrac{\delta \mu}{\delta \theta} = \dfrac{\delta e^\theta}{\delta \theta} = e^\theta  \quad \Rightarrow \quad e^\theta = \mu$$

Onde $V(\mu)$ √© chamada fun√ß√£o de vari√¢ncia e $\phi$ recebe o nome de par√¢metro de precis√£o porque quanto maior a vari√¢ncia de Y , menor ser√° o seu valor.


**Conclus√£o**  

A vari√°vel aleat√≥ria $Y$ segue uma distribui√ß√£o de Poisson com taxa de crescimento $\mu$, ou seja, $Y \sim \text{Poisson}(\mu)$. Como demonstramos, √© poss√≠vel reescrever sua fun√ß√£o de probabilidade na forma can√¥nica da fam√≠lia exponencial uniparam√©trica.  

Logo, $Y$ pertence √† fam√≠lia exponencial com par√¢metro can√¥nico $\theta = \log(\mu)$, isto √©:  
$$
Y \sim \text{FE}(\theta)
$$

<br>


**$\textcolor{blue}{\text{Passo VI: Distribui√ß√£o da Amostra (Fun√ß√£o de Verossmilhan√ßa)}}$**

Como discutido anteriormente, ao expressarmos a fun√ß√£o de densidade de probabilidade na forma da fam√≠lia exponencial, torna-se poss√≠vel construir a fun√ß√£o de verossimilhan√ßa por meio do produt√≥rio das densidades associadas a cada observa√ß√£o. Essa formula√ß√£o √© vi√°vel gra√ßas √† suposi√ß√£o de que as observa√ß√µes s√£o independentes e identicamente distribu√≠das, logo:


$$
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) 
&= \prod_{i = 1}^{n} f(y_{i};\theta_{i}) \\
&= \prod_{i = 1}^{n} \exp\left\{ y_{i}\theta_{i} - b(\theta_{i})   + c(y_{i})\right\} \\
&= \exp\left\{ y_{1}\theta_{1} - b(\theta_{1}) + c(y_{1}) \right\} \times \cdots \times \exp\left\{y_{n}\theta_{n} - b(\theta_{n}) + c(y_{n}) \right\} \\
&= \exp\left\{\sum_{i=1}^{n} y_{i}\theta_{i} - \sum_{i=1}^{n} b(\theta_{i})   + \sum_{i=1}^{n} c(y_{i}) \right\}
\end{aligned}
$$
<br>

Agora, basta substituirmos $f(y_{i};\theta_{i})$ na express√£o acima pela fun√ß√£o de probabilidade da distribui√ß√£o de Poisson, logo:


<br>

$$
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) 
&= \prod_{i = 1}^{n} \left\{\frac{\mu_{i}^{y_i} e^{-\mu_{i}}} {y_{i}!}\right\} \\
&= \prod_{i = 1}^{n} exp\left\{y_{i} \log(\mu_{i}) - e^{\mu_{i}} - log(y_{i}!) \right\} \\
&= exp\left\{y_{1} \log(\mu_{1}) - e^{\mu_{1}} - log(y_{1}!) \right\} \times \cdots \times exp\left\{y_{n} \log(\mu_{n}) - e^{\mu_{n}} - log(y_{n}!) \right\} \\
&= \exp\left\{\sum_{i=1}^{n} y_{i} \log(\mu_{i}) - \sum_{i=1}^{n} e^{\mu_{i}}   + \sum_{i=1}^{n} log(y_{i}!) \right\}
\end{aligned}
$$

<br>

**$\textcolor{blue}{\text{Passo VII: Fun√ß√£o de Log-Verossmilhan√ßa}}$**

A fun√ß√£o de log-verossimilhan√ßa com representa√ß√£o da **FE** √© dada por 

<br>

$$
\begin{aligned}
\mathcal{\ell}(\boldsymbol{\theta})  
&= \log \left\{ \mathcal{L}(\boldsymbol{\theta}) \right\} \\
&= \log \left\{ \exp\left\{\sum_{i=1}^{n} y_{i} \log(\mu_{i}) - \sum_{i=1}^{n} \mu_{i}   + \sum_{i=1}^{n} log(y_{i}!) \right\} \right\}\\
&= \sum_{i=1}^{n} y_{i} \log(\mu_{i}) - \sum_{i=1}^{n} \mu_{i}   + \sum_{i=1}^{n} log(y_{i}!)
\end{aligned}
$$



::: {.callout-note}
### Informa√ß√£o importante
**Note que at√© o momento fizemos tudo com bastante calma, explicando cada detalhe com carinho e aten√ß√£o. üíô  
Mas agora, para n√£o alongarmos demais, vamos acelerar um pouquinho nas contas, t√° bom? Prometo que, mesmo assim, vamos continuar com cuidado e sem deixar voc√™ perdido. üôÇüòä‚úåÔ∏è  
Se algo parecer confuso, respira fundo ‚Äî voc√™ pode voltar e rever com calma quando quiser. Estamos juntos nessa jornada! ‚ú®**
:::

<br>


</div>























## e) Gamma


$$
P(X = x) = \frac{e^{-\lambda} \lambda^x}{x!}, \quad x = 0, 1, 2, \dots
$$

## f) Normal Inversa


$$
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}, \quad k = 0, 1, \dots, n
$$

## Dirichlet

$$
f(x_1, \ldots, x_k \;|\; \alpha_1, \ldots, \alpha_k) = \frac{\Gamma\left(\sum_{i=1}^{k} \alpha_i \right)}{\prod_{i=1}^{k} \Gamma(\alpha_i)} \prod_{i=1}^{k} x_i^{\alpha_i - 1}, \quad \text{para } x_i \geq 0 \text{ e } \sum_{i=1}^{k} x_i = 1.
$$

:::




